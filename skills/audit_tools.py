# skills/audit_tools.py
# å·¥å…·è°ƒç”¨å®¡è®¡é“¾ï¼šè®°å½•æ¯æ¬¡å·¥å…·è°ƒç”¨çš„å…¨é“¾è·¯æ—¥å¿—ï¼Œæ”¯æŒæŸ¥è¯¢å’Œç»Ÿè®¡

import os
import json
import time
from pathlib import Path
from .registry import register
from .path_safety import guard_path, WORKSPACE_ROOT

AUDIT_LOG_REL = "data/audit_log.jsonl"
MAX_QUERY_RESULTS = 50


def _display_path(path_obj):
    try:
        return str(path_obj.relative_to(WORKSPACE_ROOT))
    except Exception:
        return str(path_obj)


def _audit_file():
    file_obj, err = guard_path(AUDIT_LOG_REL, must_exist=False, for_write=True)
    if err:
        raise ValueError(err)
    if not file_obj.parent.exists():
        file_obj.parent.mkdir(parents=True, exist_ok=True)
    return file_obj


def log_tool_call(func_name: str, args: dict, result_str: str, elapsed_ms: float = 0):
    """Append one audit record. Called from engine.py after each tool execution."""
    try:
        file_obj = _audit_file()

        # Truncate large argument values for storage
        safe_args = {}
        for k, v in (args or {}).items():
            s = str(v)
            safe_args[k] = s[:200] + "..." if len(s) > 200 else s

        # Truncate result
        result_preview = str(result_str or "")
        if len(result_preview) > 500:
            result_preview = result_preview[:500] + "..."

        record = {
            "ts": time.strftime("%Y-%m-%d %H:%M:%S"),
            "epoch": time.time(),
            "tool": func_name,
            "args_summary": safe_args,
            "result_preview": result_preview,
            "success": not result_preview.startswith("âŒ"),
            "elapsed_ms": round(elapsed_ms, 1),
        }

        with open(file_obj, 'a', encoding='utf-8') as f:
            f.write(json.dumps(record, ensure_ascii=False) + "\n")

    except Exception:
        pass  # audit must never break the main flow


def _read_audit_lines(max_lines=500):
    """Read recent audit entries."""
    file_obj = _audit_file()
    if not file_obj.exists():
        return []

    lines = []
    with open(file_obj, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line:
                lines.append(line)

    # Keep only the most recent entries
    return lines[-max_lines:]


# ==========================================
# 1. æŸ¥è¯¢å®¡è®¡æ—¥å¿—
# ==========================================
audit_query_schema = {
    "type": "function",
    "function": {
        "name": "audit_query",
        "description": (
            "æŸ¥è¯¢å·¥å…·è°ƒç”¨å®¡è®¡æ—¥å¿—ã€‚å¯ä»¥æŒ‰å·¥å…·åã€æ—¶é—´èŒƒå›´ã€æˆåŠŸ/å¤±è´¥è¿›è¡Œç­›é€‰ã€‚"
            "å¸®åŠ©å›é¡¾å†å²æ“ä½œå’Œæ’æŸ¥é—®é¢˜ã€‚"
        ),
        "parameters": {
            "type": "object",
            "properties": {
                "tool_name": {"type": "string", "description": "æŒ‰å·¥å…·åç­›é€‰ï¼ˆæ”¯æŒéƒ¨åˆ†åŒ¹é…ï¼‰"},
                "last_n": {"type": "integer", "description": "æŸ¥çœ‹æœ€è¿‘ N æ¡è®°å½•ï¼Œé»˜è®¤ 20"},
                "only_errors": {"type": "boolean", "description": "ä»…æ˜¾ç¤ºå¤±è´¥è®°å½•ï¼Œé»˜è®¤ false"},
                "date": {"type": "string", "description": "æŒ‰æ—¥æœŸç­›é€‰ (YYYY-MM-DD)"},
            },
            "required": [],
        },
    },
}


@register(audit_query_schema)
def audit_query(tool_name: str = "", last_n: int = 20, only_errors: bool = False, date: str = ""):
    """æŸ¥è¯¢å®¡è®¡æ—¥å¿—"""
    try:
        raw_lines = _read_audit_lines(500)
        if not raw_lines:
            return "ğŸ“‹ å®¡è®¡æ—¥å¿—ä¸ºç©ºï¼Œå°šæ— å·¥å…·è°ƒç”¨è®°å½•ã€‚"

        records = []
        for line in raw_lines:
            try:
                records.append(json.loads(line))
            except Exception:
                continue

        # Apply filters
        if tool_name:
            tool_name_lower = tool_name.lower()
            records = [r for r in records if tool_name_lower in r.get("tool", "").lower()]

        if only_errors:
            records = [r for r in records if not r.get("success", True)]

        if date:
            records = [r for r in records if r.get("ts", "").startswith(date)]

        last_n = max(1, min(int(last_n) if last_n else 20, MAX_QUERY_RESULTS))
        records = records[-last_n:]

        if not records:
            return "ğŸ“‹ æ²¡æœ‰åŒ¹é…çš„å®¡è®¡è®°å½•"

        lines = [f"ğŸ“‹ å®¡è®¡æ—¥å¿— (æ˜¾ç¤º {len(records)} æ¡):\n"]
        for r in records:
            status = "âœ…" if r.get("success", True) else "âŒ"
            elapsed = f" ({r['elapsed_ms']}ms)" if r.get("elapsed_ms") else ""
            lines.append(f"  {status} [{r.get('ts', '?')}] {r.get('tool', '?')}{elapsed}")

            args_summary = r.get("args_summary", {})
            if args_summary:
                brief = ", ".join(f"{k}={v}" for k, v in list(args_summary.items())[:3])
                if len(brief) > 120:
                    brief = brief[:120] + "..."
                lines.append(f"     å‚æ•°: {brief}")

            result = r.get("result_preview", "")
            if result:
                one_line = result.split("\n")[0][:100]
                lines.append(f"     ç»“æœ: {one_line}")
            lines.append("")

        return "\n".join(lines)

    except Exception as e:
        return f"âŒ æŸ¥è¯¢å®¡è®¡æ—¥å¿—å¤±è´¥: {e}"


# ==========================================
# 2. å®¡è®¡ç»Ÿè®¡
# ==========================================
audit_stats_schema = {
    "type": "function",
    "function": {
        "name": "audit_stats",
        "description": "ç»Ÿè®¡å·¥å…·è°ƒç”¨æƒ…å†µï¼šè°ƒç”¨æ¬¡æ•°ã€æˆåŠŸç‡ã€æœ€å¸¸ç”¨å·¥å…·ã€å¹³å‡è€—æ—¶ç­‰ã€‚",
        "parameters": {
            "type": "object",
            "properties": {
                "date": {"type": "string", "description": "æŒ‰æ—¥æœŸç­›é€‰ (YYYY-MM-DD)ï¼Œç•™ç©ºç»Ÿè®¡å…¨éƒ¨"},
            },
            "required": [],
        },
    },
}


@register(audit_stats_schema)
def audit_stats(date: str = ""):
    """å®¡è®¡ç»Ÿè®¡"""
    try:
        raw_lines = _read_audit_lines(2000)
        if not raw_lines:
            return "ğŸ“Š å®¡è®¡æ—¥å¿—ä¸ºç©º"

        records = []
        for line in raw_lines:
            try:
                records.append(json.loads(line))
            except Exception:
                continue

        if date:
            records = [r for r in records if r.get("ts", "").startswith(date)]

        if not records:
            return f"ğŸ“Š æ²¡æœ‰{'åŒ¹é…æ—¥æœŸ ' + date + ' çš„' if date else ''}å®¡è®¡è®°å½•"

        total = len(records)
        successes = sum(1 for r in records if r.get("success", True))
        failures = total - successes

        # Tool frequency
        tool_counts = {}
        tool_times = {}
        for r in records:
            name = r.get("tool", "unknown")
            tool_counts[name] = tool_counts.get(name, 0) + 1
            elapsed = r.get("elapsed_ms", 0)
            if elapsed:
                tool_times.setdefault(name, []).append(elapsed)

        sorted_tools = sorted(tool_counts.items(), key=lambda x: x[1], reverse=True)

        date_label = f" ({date})" if date else ""
        lines = [f"ğŸ“Š å·¥å…·è°ƒç”¨ç»Ÿè®¡{date_label}:\n"]
        lines.append(f"  æ€»è°ƒç”¨æ¬¡æ•°: {total}")
        lines.append(f"  æˆåŠŸ: {successes} ({successes*100//total}%)")
        lines.append(f"  å¤±è´¥: {failures} ({failures*100//total}%)")

        lines.append(f"\n  ğŸ”§ å·¥å…·ä½¿ç”¨æ’è¡Œ (Top 10):")
        for name, count in sorted_tools[:10]:
            avg_ms = ""
            if name in tool_times and tool_times[name]:
                avg = sum(tool_times[name]) / len(tool_times[name])
                avg_ms = f"  avg {avg:.0f}ms"
            lines.append(f"    {count:3d}x  {name}{avg_ms}")

        # Time range
        if records:
            first_ts = records[0].get("ts", "?")
            last_ts = records[-1].get("ts", "?")
            lines.append(f"\n  ğŸ“… è®°å½•èŒƒå›´: {first_ts} ~ {last_ts}")

        return "\n".join(lines)

    except Exception as e:
        return f"âŒ ç»Ÿè®¡å¤±è´¥: {e}"
