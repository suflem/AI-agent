# skills/grad_school_tools.py
# ç ”ç©¶ç”Ÿæ‹©æ ¡å·¥å…·ï¼šèµ„æ–™å½•å…¥ã€æ£€ç´¢è½åº“ã€å¤šæ ¡å¯¹æ¯”

import json
import os
import re
import time
from datetime import datetime, timedelta
from pathlib import Path

from .registry import register
from .path_safety import guard_path, WORKSPACE_ROOT


GRAD_DIR = "data/grad_school"
PROFILES_FILE = "profiles.json"
PROFILE_DOCS_DIR = "profiles_docs"
WEB_CACHE_DIR = "web_cache"


def _display_path(path_obj: Path):
    try:
        return str(path_obj.relative_to(WORKSPACE_ROOT))
    except Exception:
        return str(path_obj)


def _ensure_grad_dir():
    grad_obj, err = guard_path(GRAD_DIR, must_exist=False, for_write=True)
    if err:
        raise ValueError(err)
    if not grad_obj.exists():
        grad_obj.mkdir(parents=True, exist_ok=True)
    return grad_obj


def _grad_file(filename: str):
    grad_obj = _ensure_grad_dir()
    path_obj, err = guard_path(str(grad_obj / filename), must_exist=False, for_write=True)
    if err:
        raise ValueError(err)
    return path_obj


def _load_profiles():
    file_obj = _grad_file(PROFILES_FILE)
    if file_obj.exists():
        with open(file_obj, "r", encoding="utf-8") as f:
            data = json.load(f)
            if isinstance(data, list):
                return data
    return []


def _save_profiles(items):
    file_obj = _grad_file(PROFILES_FILE)
    with open(file_obj, "w", encoding="utf-8") as f:
        json.dump(items, f, ensure_ascii=False, indent=2)


def _parse_json_object(text: str):
    raw = (text or "").strip()
    if not raw:
        return {}
    try:
        obj = json.loads(raw)
        return obj if isinstance(obj, dict) else {"raw_text": raw}
    except Exception:
        return {"raw_text": raw}


def _slugify(text: str):
    s = re.sub(r"[^A-Za-z0-9_-]+", "_", (text or "").strip())
    s = re.sub(r"_+", "_", s).strip("_")
    return s[:64] or "item"


def _ensure_subdir(name: str):
    grad_obj = _ensure_grad_dir()
    sub_obj = grad_obj / name
    if not sub_obj.exists():
        sub_obj.mkdir(parents=True, exist_ok=True)
    return sub_obj


def _profile_key(school: str, program: str):
    return f"{(school or '').strip().lower()}::{(program or '').strip().lower()}"


def _clamp_score(value, low=0.0, high=100.0):
    try:
        x = float(value)
    except Exception:
        x = 0.0
    if x < low:
        return low
    if x > high:
        return high
    return x


def _to_float(value, default=None):
    if value is None:
        return default
    if isinstance(value, (int, float)):
        return float(value)
    s = str(value).strip()
    if not s:
        return default
    m = re.search(r"-?\d+(\.\d+)?", s)
    if not m:
        return default
    try:
        return float(m.group(0))
    except Exception:
        return default


def _parse_date(value: str):
    if not value:
        return None
    s = str(value).strip()
    if not s:
        return None
    fmts = (
        "%Y-%m-%d",
        "%Y/%m/%d",
        "%Y.%m.%d",
        "%Y%m%d",
        "%Y-%m-%d %H:%M",
        "%Y/%m/%d %H:%M",
        "%Y.%m.%d %H:%M",
    )
    for fmt in fmts:
        try:
            return datetime.strptime(s, fmt)
        except Exception:
            pass

    m = re.search(r"(\d{4})[-/.](\d{1,2})[-/.](\d{1,2})", s)
    if m:
        try:
            y, mo, d = int(m.group(1)), int(m.group(2)), int(m.group(3))
            return datetime(y, mo, d)
        except Exception:
            return None
    return None


def _extract_deadline(profile: dict):
    info = profile.get("info", {}) if isinstance(profile.get("info", {}), dict) else {}
    candidates = [
        info.get("application_deadline"),
        info.get("deadline"),
        info.get("ddl"),
        info.get("deadline_date"),
    ]
    if isinstance(info.get("deadlines"), dict):
        dct = info.get("deadlines", {})
        candidates.extend([
            dct.get("application"),
            dct.get("final"),
            dct.get("priority"),
        ])
    for item in candidates:
        dt = _parse_date(item)
        if dt:
            return dt
    return None


def _filter_profiles(profiles, schools: str, program: str):
    selected = profiles
    target_schools = [x.strip() for x in (schools or "").split(",") if x.strip()]
    if target_schools:
        keyset = {x.lower() for x in target_schools}
        selected = [p for p in selected if p.get("school", "").strip().lower() in keyset]
    if program:
        pkey = program.strip().lower()
        selected = [p for p in selected if p.get("program", "").strip().lower() == pkey]
    return selected


def _normalize_weights(weights_obj):
    default_weights = {
        "research_fit": 0.35,
        "admission_feasibility": 0.25,
        "cost_funding": 0.2,
        "location_career": 0.2,
    }
    if not isinstance(weights_obj, dict) or not weights_obj:
        return default_weights

    cleaned = {}
    for k, v in weights_obj.items():
        if k not in default_weights:
            continue
        fv = _to_float(v, None)
        if fv is None or fv < 0:
            continue
        cleaned[k] = fv
    if not cleaned:
        return default_weights

    total = sum(cleaned.values())
    if total <= 0:
        return default_weights
    return {k: v / total for k, v in cleaned.items()}


def _keyword_set(value):
    if isinstance(value, list):
        raw = " ".join([str(x) for x in value])
    elif isinstance(value, dict):
        raw = " ".join([str(v) for v in value.values()])
    else:
        raw = str(value or "")
    parts = re.split(r"[,;/|\s]+", raw.lower())
    return {p.strip() for p in parts if p.strip()}


def _score_research_fit(profile: dict, user_profile: dict):
    info = profile.get("info", {}) if isinstance(profile.get("info", {}), dict) else {}
    explicit = (
        _to_float(info.get("research_fit_score"), None)
        or _to_float((info.get("scores", {}) or {}).get("research_fit"), None)
    )
    if explicit is not None:
        return _clamp_score(explicit)

    school_text = " ".join([
        str(profile.get("program", "")),
        str(info.get("research_areas", "")),
        str(info.get("faculty_interests", "")),
        str(info.get("lab_keywords", "")),
    ])
    user_text = " ".join([
        str(user_profile.get("target_interest", "")),
        str(user_profile.get("research_interests", "")),
        str(user_profile.get("keywords", "")),
    ])
    a = _keyword_set(school_text)
    b = _keyword_set(user_text)
    if not a or not b:
        return 60.0
    overlap = len(a.intersection(b))
    return _clamp_score(50 + overlap * 12)


def _score_admission(profile: dict, user_profile: dict):
    info = profile.get("info", {}) if isinstance(profile.get("info", {}), dict) else {}
    explicit = (
        _to_float(info.get("admission_feasibility_score"), None)
        or _to_float((info.get("scores", {}) or {}).get("admission_feasibility"), None)
    )
    if explicit is not None:
        return _clamp_score(explicit)

    score = 60.0
    ugpa = _to_float(user_profile.get("gpa"), None)
    rgpa = _to_float(info.get("min_gpa"), None)
    if rgpa is None:
        rgpa = _to_float(info.get("required_gpa"), None)
    if ugpa is not None and rgpa is not None:
        score += (ugpa - rgpa) * 25

    ugre = _to_float(user_profile.get("gre"), None)
    rgre = _to_float(info.get("min_gre"), None)
    if rgre is None:
        rgre = _to_float(info.get("required_gre"), None)
    if ugre is not None and rgre is not None:
        score += (ugre - rgre) / 2.5

    accept_rate = _to_float(info.get("acceptance_rate"), None)
    if accept_rate is not None:
        if accept_rate <= 1:
            accept_rate *= 100
        score += (accept_rate - 20) * 0.4

    return _clamp_score(score)


def _score_cost(profile: dict, user_profile: dict):
    info = profile.get("info", {}) if isinstance(profile.get("info", {}), dict) else {}
    explicit = (
        _to_float(info.get("cost_funding_score"), None)
        or _to_float((info.get("scores", {}) or {}).get("cost_funding"), None)
    )
    if explicit is not None:
        return _clamp_score(explicit)

    tuition = (
        _to_float(info.get("tuition_usd"), None)
        or _to_float(info.get("tuition"), None)
        or _to_float(info.get("per_year_tuition"), None)
    )
    funding = _to_float(info.get("funding_rate"), None)
    budget = _to_float(user_profile.get("budget_usd"), None)

    score = 65.0
    if tuition is not None:
        score = 100 - tuition / 900
    if budget is not None and tuition is not None:
        score += (budget - tuition) / 1500
    if funding is not None:
        if funding <= 1:
            funding *= 100
        score += (funding - 25) * 0.3
    return _clamp_score(score)


def _score_location(profile: dict, user_profile: dict):
    info = profile.get("info", {}) if isinstance(profile.get("info", {}), dict) else {}
    explicit = (
        _to_float(info.get("location_career_score"), None)
        or _to_float((info.get("scores", {}) or {}).get("location_career"), None)
    )
    if explicit is not None:
        return _clamp_score(explicit)

    pref = _keyword_set(user_profile.get("preferred_locations", ""))
    career = _keyword_set(user_profile.get("career_goal", ""))
    loc_text = " ".join([
        str(info.get("location", "")),
        str(info.get("city", "")),
        str(info.get("country", "")),
        str(info.get("career_outcomes", "")),
    ])
    pset = _keyword_set(loc_text)

    score = 60.0
    if pref and pset:
        score += len(pref.intersection(pset)) * 12
    if career and pset:
        score += len(career.intersection(pset)) * 8
    return _clamp_score(score)


def _tier_by_admission(admission_score: float):
    if admission_score < 45:
        return "å†²åˆº"
    if admission_score < 70:
        return "åŒ¹é…"
    return "ä¿åº•"


grad_school_manage_schema = {
    "type": "function",
    "function": {
        "name": "grad_school_manage",
        "description": (
            "ç®¡ç†ç ”ç©¶ç”Ÿæ‹©æ ¡èµ„æ–™ã€‚æ”¯æŒå½•å…¥/æ›´æ–°å­¦æ ¡æ¡£æ¡ˆã€æŸ¥çœ‹åˆ—è¡¨ã€åˆ é™¤ã€å¯¼å‡ºåˆ°çŸ¥è¯†åº“æ–‡æ¡£æºã€‚"
        ),
        "parameters": {
            "type": "object",
            "properties": {
                "action": {
                    "type": "string",
                    "description": "æ“ä½œ: upsert/get/list/remove/build_kb_source"
                },
                "school": {"type": "string", "description": "å­¦æ ¡åç§°"},
                "program": {"type": "string", "description": "é¡¹ç›®/ä¸“ä¸šåç§°"},
                "intake": {"type": "string", "description": "ç”³è¯·å­¦æœŸï¼Œå¦‚ 2027 Fall"},
                "info_json": {"type": "string", "description": "è¡¥å……ä¿¡æ¯(JSONå¯¹è±¡æˆ–çº¯æ–‡æœ¬)"},
                "top_n": {"type": "integer", "description": "list æ—¶è¿”å›æ¡æ•°ï¼Œé»˜è®¤ 20"}
            },
            "required": ["action"]
        }
    }
}


@register(grad_school_manage_schema)
def grad_school_manage(
    action: str,
    school: str = "",
    program: str = "",
    intake: str = "",
    info_json: str = "",
    top_n: int = 20,
):
    try:
        action = (action or "").strip().lower()
        profiles = _load_profiles()

        if action == "list":
            if not profiles:
                return "ğŸ“ æš‚æ— æ‹©æ ¡æ¡£æ¡ˆ"
            top_n = max(1, min(int(top_n) if top_n else 20, 100))
            lines = [f"ğŸ“ æ‹©æ ¡æ¡£æ¡ˆ ({len(profiles)} æ¡):\n"]
            for idx, p in enumerate(profiles[:top_n], 1):
                lines.append(
                    f"  {idx}. {p.get('school', '?')} | {p.get('program', '?')} | {p.get('intake', '-')}"
                )
                lines.append(f"     æ›´æ–°: {p.get('updated_at', '-')}")
            return "\n".join(lines)

        if action == "get":
            if not school:
                return "âŒ get éœ€è¦ school"
            key = _profile_key(school, program)
            candidates = [p for p in profiles if _profile_key(p.get("school", ""), p.get("program", "")) == key]
            if not candidates:
                # program ä¸ºç©ºæ—¶å…è®¸æŒ‰ school æ¨¡ç³Šå–ç¬¬ä¸€æ¡
                if not program:
                    candidates = [p for p in profiles if p.get("school", "").strip().lower() == school.strip().lower()]
            if not candidates:
                return f"âŒ æœªæ‰¾åˆ°æ¡£æ¡ˆ: {school} / {program or '*'}"
            return "ğŸ“ æ¡£æ¡ˆè¯¦æƒ…:\n" + json.dumps(candidates[0], ensure_ascii=False, indent=2)

        if action == "remove":
            if not school:
                return "âŒ remove éœ€è¦ school"
            before = len(profiles)
            if program:
                key = _profile_key(school, program)
                profiles = [p for p in profiles if _profile_key(p.get("school", ""), p.get("program", "")) != key]
            else:
                s = school.strip().lower()
                profiles = [p for p in profiles if p.get("school", "").strip().lower() != s]
            if len(profiles) == before:
                return "âŒ æœªåˆ é™¤ä»»ä½•æ¡£æ¡ˆï¼ˆæœªåŒ¹é…ï¼‰"
            _save_profiles(profiles)
            return f"âœ… å·²åˆ é™¤ {before - len(profiles)} æ¡æ¡£æ¡ˆ"

        if action == "upsert":
            if not school or not program:
                return "âŒ upsert éœ€è¦ school å’Œ program"
            ext_info = _parse_json_object(info_json)
            key = _profile_key(school, program)

            updated = False
            now_str = time.strftime("%Y-%m-%d %H:%M")
            for p in profiles:
                if _profile_key(p.get("school", ""), p.get("program", "")) == key:
                    p["intake"] = intake or p.get("intake", "")
                    p["info"] = ext_info or p.get("info", {})
                    p["updated_at"] = now_str
                    updated = True
                    break
            if not updated:
                profiles.append({
                    "school": school.strip(),
                    "program": program.strip(),
                    "intake": (intake or "").strip(),
                    "info": ext_info,
                    "created_at": now_str,
                    "updated_at": now_str,
                })
            _save_profiles(profiles)
            return f"âœ… å·²{'æ›´æ–°' if updated else 'æ–°å¢'}æ¡£æ¡ˆ: {school} / {program}"

        if action == "build_kb_source":
            docs_dir = _ensure_subdir(PROFILE_DOCS_DIR)
            if not profiles:
                return "âŒ æ²¡æœ‰å¯å¯¼å‡ºçš„æ¡£æ¡ˆ"

            written = 0
            for p in profiles:
                school_name = p.get("school", "")
                program_name = p.get("program", "")
                filename = f"{_slugify(school_name)}__{_slugify(program_name)}.md"
                fpath = docs_dir / filename
                md = [
                    f"# {school_name} - {program_name}",
                    "",
                    f"- intake: {p.get('intake', '')}",
                    f"- updated_at: {p.get('updated_at', '')}",
                    "",
                    "## profile_info",
                    "```json",
                    json.dumps(p.get("info", {}), ensure_ascii=False, indent=2),
                    "```",
                    "",
                ]
                with open(fpath, "w", encoding="utf-8") as f:
                    f.write("\n".join(md))
                written += 1

            return (
                f"âœ… å·²å¯¼å‡º {written} ä»½æ‹©æ ¡èµ„æ–™æ–‡æ¡£\n"
                f"ğŸ“ è·¯å¾„: {_display_path(docs_dir)}\n"
                "ğŸ’¡ ä¸‹ä¸€æ­¥å¯ç”¨ kb_build(kb_name='grad_school_kb', source_path='data/grad_school/profiles_docs')"
            )

        return "âŒ æœªçŸ¥ actionã€‚æ”¯æŒ: upsert/get/list/remove/build_kb_source"
    except Exception as e:
        return f"âŒ æ‹©æ ¡èµ„æ–™ç®¡ç†å¤±è´¥: {e}"


grad_school_research_schema = {
    "type": "function",
    "function": {
        "name": "grad_school_research",
        "description": (
            "è”ç½‘æœç´¢é™¢æ ¡/ä¸“ä¸šä¿¡æ¯ï¼ŒæŠ“å–ç½‘é¡µåå­˜å…¥æœ¬åœ°ç¼“å­˜ï¼Œå¹¶å¯ä¸€é”®æ„å»º/æ›´æ–°æ‹©æ ¡çŸ¥è¯†åº“ã€‚"
        ),
        "parameters": {
            "type": "object",
            "properties": {
                "query": {"type": "string", "description": "æœç´¢å…³é”®è¯"},
                "max_results": {"type": "integer", "description": "æœ€å¤šæŠ“å–ç»“æœæ•°ï¼Œé»˜è®¤ 5"},
                "kb_name": {"type": "string", "description": "è½åœ°çŸ¥è¯†åº“åç§°ï¼Œé»˜è®¤ grad_school_kb"},
                "build_kb": {"type": "boolean", "description": "æ˜¯å¦è‡ªåŠ¨æ„å»ºçŸ¥è¯†åº“ï¼Œé»˜è®¤ true"},
                "fetch_chars": {"type": "integer", "description": "å•é¡µæŠ“å–å­—ç¬¦æ•°ï¼Œé»˜è®¤ 8000"}
            },
            "required": ["query"]
        }
    }
}


@register(grad_school_research_schema)
def grad_school_research(
    query: str,
    max_results: int = 5,
    kb_name: str = "grad_school_kb",
    build_kb: bool = True,
    fetch_chars: int = 8000,
):
    try:
        from .web_tools import web_search, fetch_url
        from .knowledge_tools import kb_build

        max_results = max(1, min(int(max_results) if max_results else 5, 10))
        fetch_chars = max(2000, min(int(fetch_chars) if fetch_chars else 8000, 20000))

        raw_search = web_search(query=query, num_results=max_results)
        if not isinstance(raw_search, str):
            return "âŒ æœç´¢å¤±è´¥: web_search è¿”å›äº†éæ–‡æœ¬ç»“æœ"
        if raw_search.startswith("âŒ"):
            return raw_search

        urls = re.findall(r"https?://[^\s)]+", raw_search)
        dedup_urls = []
        seen = set()
        for u in urls:
            if u not in seen:
                dedup_urls.append(u)
                seen.add(u)
        dedup_urls = dedup_urls[:max_results]
        if not dedup_urls:
            return f"âš ï¸ æœç´¢ç»“æœä¸­æœªè§£æåˆ°å¯æŠ“å–é“¾æ¥\n{raw_search}"

        cache_dir = _ensure_subdir(WEB_CACHE_DIR)
        saved = 0
        failed = []
        ts = int(time.time())
        for idx, url in enumerate(dedup_urls, 1):
            fetched = fetch_url(url=url, max_length=fetch_chars)
            if not isinstance(fetched, str) or fetched.startswith("âŒ"):
                failed.append(f"{url} -> {fetched}")
                continue
            fname = f"{ts}_{idx}_{_slugify(query)[:32]}.md"
            fpath = cache_dir / fname
            with open(fpath, "w", encoding="utf-8") as f:
                f.write(f"# query: {query}\n\nsource: {url}\n\n{fetched}\n")
            saved += 1

        lines = [
            f"ğŸ” æ‹©æ ¡è”ç½‘æ£€ç´¢å®Œæˆ: {query}",
            f"  è§£æé“¾æ¥: {len(dedup_urls)}",
            f"  æˆåŠŸç¼“å­˜: {saved}",
            f"  å¤±è´¥: {len(failed)}",
            f"  ç¼“å­˜ç›®å½•: {_display_path(cache_dir)}",
        ]

        if build_kb and saved > 0:
            build_result = kb_build(
                kb_name=kb_name,
                source_path=str(cache_dir),
                file_pattern="*.md",
                chunk_size=700,
            )
            lines.append("")
            lines.append("ğŸ“š çŸ¥è¯†åº“æ›´æ–°ç»“æœ:")
            lines.append(str(build_result))

        if failed:
            lines.append("")
            lines.append("âš ï¸ å¤±è´¥æ ·ä¾‹:")
            lines.extend([f"  - {x}" for x in failed[:5]])

        return "\n".join(lines)
    except Exception as e:
        return f"âŒ æ‹©æ ¡è”ç½‘æ£€ç´¢å¤±è´¥: {e}"


grad_school_compare_schema = {
    "type": "function",
    "function": {
        "name": "grad_school_compare",
        "description": (
            "å¯¹å¤šæ‰€å­¦æ ¡/é¡¹ç›®è¿›è¡Œç»“æ„åŒ–å¯¹æ¯”ï¼Œè¾“å‡ºä¼˜å…ˆçº§å»ºè®®å’Œé€‰æ ¡ç†ç”±ã€‚"
            "å¯ç»“åˆæœ¬åœ°æ¡£æ¡ˆä¸æ‹©æ ¡çŸ¥è¯†åº“ã€‚"
        ),
        "parameters": {
            "type": "object",
            "properties": {
                "schools": {"type": "string", "description": "å­¦æ ¡ååˆ—è¡¨ï¼Œé€—å·åˆ†éš”ï¼›ç•™ç©ºè¡¨ç¤ºå…¨éƒ¨æ¡£æ¡ˆ"},
                "program": {"type": "string", "description": "é™å®šä¸“ä¸šï¼ˆå¯é€‰ï¼‰"},
                "criteria_weights": {
                    "type": "string",
                    "description": "æƒé‡ JSONï¼Œå¦‚ {\"research_fit\":0.35,\"admission\":0.25,\"cost\":0.2,\"location\":0.2}"
                },
                "kb_name": {"type": "string", "description": "å¯é€‰çŸ¥è¯†åº“åç§°ï¼ˆå¦‚ grad_school_kbï¼‰"},
                "top_k": {"type": "integer", "description": "æ¯æ ¡æ£€ç´¢ç‰‡æ®µæ•°ï¼Œé»˜è®¤ 4"}
            },
            "required": []
        }
    }
}


@register(grad_school_compare_schema)
def grad_school_compare(
    schools: str = "",
    program: str = "",
    criteria_weights: str = "",
    kb_name: str = "",
    top_k: int = 4,
):
    try:
        from .external_ai import call_ai
        from .knowledge_tools import kb_query

        profiles = _load_profiles()
        if not profiles:
            return "âŒ æ²¡æœ‰å¯å¯¹æ¯”çš„æ‹©æ ¡æ¡£æ¡ˆï¼Œè¯·å…ˆ grad_school_manage(action='upsert') å½•å…¥ã€‚"

        selected = _filter_profiles(profiles, schools=schools, program=program)

        if len(selected) < 2:
            return "âŒ è‡³å°‘éœ€è¦ 2 ä¸ªé¡¹ç›®è¿›è¡Œå¯¹æ¯”ï¼ˆå½“å‰ä¸è¶³ï¼‰ã€‚"

        top_k = max(2, min(int(top_k) if top_k else 4, 10))
        weights = _normalize_weights(_parse_json_object(criteria_weights))

        kb_context = {}
        if kb_name:
            for p in selected:
                sname = p.get("school", "")
                pname = p.get("program", "")
                q = f"{sname} {pname} admission requirement tuition scholarship faculty research"
                kb_context[f"{sname}::{pname}"] = kb_query(kb_name=kb_name, query=q, top_k=top_k)

        prompt_payload = {
            "profiles": selected,
            "criteria_weights": weights,
            "kb_context": kb_context,
        }

        result = call_ai(
            prompt=(
                "è¯·å¯¹ä»¥ä¸‹ç ”ç©¶ç”Ÿç”³è¯·é€‰é¡¹åšç»“æ„åŒ–å¯¹æ¯”ã€‚\n"
                "è¾“å‡ºæ ¼å¼ï¼š\n"
                "1) å¯¹æ¯”æ€»è§ˆè¡¨ï¼ˆæ¯æ ¡æ¯ç»´åº¦ç®€è¯„ï¼‰\n"
                "2) æ’åä¸åˆ†å±‚ï¼ˆå†²åˆº/åŒ¹é…/ä¿åº•ï¼‰\n"
                "3) æ¯ä¸ªé€‰é¡¹çš„æ ¸å¿ƒé£é™©\n"
                "4) æœ€ç»ˆå»ºè®®ï¼ˆå«ä¸‹ä¸€æ­¥è¡ŒåŠ¨æ¸…å•ï¼‰\n\n"
                f"è¾“å…¥æ•°æ®:\n{json.dumps(prompt_payload, ensure_ascii=False, indent=2)}"
            ),
            provider="kimi",
            system_prompt=(
                "ä½ æ˜¯ç ”ç©¶ç”Ÿç”³è¯·é¡¾é—®ã€‚å¿…é¡»ä¾æ®è¾“å…¥ææ–™ï¼Œä¸ç¼–é€ å½•å–ç‡å’Œå¥–å­¦é‡‘ã€‚"
                "ä¿¡æ¯ä¸è¶³è¦ç›´æ¥æ ‡æ³¨â€œå¾…è¡¥å……â€ã€‚"
            ),
            temperature=0.3,
            max_tokens=4096,
        )
        return f"ğŸ« æ‹©æ ¡å¯¹æ¯”ç»“æœ\n{result}"
    except Exception as e:
        return f"âŒ æ‹©æ ¡å¯¹æ¯”å¤±è´¥: {e}"


grad_school_scorecard_schema = {
    "type": "function",
    "function": {
        "name": "grad_school_scorecard",
        "description": (
            "åŸºäºå¯é…ç½®æƒé‡ç”Ÿæˆæ‹©æ ¡é‡åŒ–è¯„åˆ†å¡ï¼Œå¹¶ç»™å‡ºå†²åˆº/åŒ¹é…/ä¿åº•åˆ†å±‚ã€‚"
        ),
        "parameters": {
            "type": "object",
            "properties": {
                "schools": {"type": "string", "description": "å­¦æ ¡ååˆ—è¡¨ï¼Œé€—å·åˆ†éš”ï¼›ç•™ç©ºè¡¨ç¤ºå…¨éƒ¨æ¡£æ¡ˆ"},
                "program": {"type": "string", "description": "é™å®šä¸“ä¸šï¼ˆå¯é€‰ï¼‰"},
                "user_profile_json": {
                    "type": "string",
                    "description": "ç”¨æˆ·ç”»åƒ JSONï¼Œå¦‚ GPA/GRE/é¢„ç®—/ç ”ç©¶å…´è¶£/åŸå¸‚åå¥½"
                },
                "criteria_weights": {
                    "type": "string",
                    "description": "æƒé‡ JSONï¼Œå¦‚ {\"research_fit\":0.35,\"admission_feasibility\":0.3,\"cost_funding\":0.2,\"location_career\":0.15}"
                },
                "sort_by": {
                    "type": "string",
                    "description": "æ’åºå­—æ®µ: total/research_fit/admission_feasibility/cost_funding/location_career"
                },
                "top_n": {"type": "integer", "description": "æœ€å¤šè¿”å›æ¡ç›®æ•°ï¼Œé»˜è®¤ 20"}
            },
            "required": []
        }
    }
}


@register(grad_school_scorecard_schema)
def grad_school_scorecard(
    schools: str = "",
    program: str = "",
    user_profile_json: str = "",
    criteria_weights: str = "",
    sort_by: str = "total",
    top_n: int = 20,
):
    try:
        profiles = _load_profiles()
        if not profiles:
            return "âŒ æ²¡æœ‰å¯è¯„åˆ†æ¡£æ¡ˆï¼Œè¯·å…ˆ grad_school_manage(action='upsert') å½•å…¥ã€‚"

        selected = _filter_profiles(profiles, schools=schools, program=program)
        if not selected:
            return "âŒ æœªç­›é€‰åˆ°å¯è¯„åˆ†æ¡£æ¡ˆ"

        user_profile = _parse_json_object(user_profile_json)
        weights = _normalize_weights(_parse_json_object(criteria_weights))
        top_n = max(1, min(int(top_n) if top_n else 20, 100))

        rows = []
        for p in selected:
            s_research = _score_research_fit(p, user_profile)
            s_adm = _score_admission(p, user_profile)
            s_cost = _score_cost(p, user_profile)
            s_loc = _score_location(p, user_profile)
            details = {
                "research_fit": s_research,
                "admission_feasibility": s_adm,
                "cost_funding": s_cost,
                "location_career": s_loc,
            }
            total = 0.0
            for k, w in weights.items():
                total += details.get(k, 0.0) * w

            rows.append({
                "school": p.get("school", ""),
                "program": p.get("program", ""),
                "total": round(total, 1),
                "research_fit": round(s_research, 1),
                "admission_feasibility": round(s_adm, 1),
                "cost_funding": round(s_cost, 1),
                "location_career": round(s_loc, 1),
                "tier": _tier_by_admission(s_adm),
            })

        sort_key = (sort_by or "total").strip()
        if sort_key not in {
            "total", "research_fit", "admission_feasibility", "cost_funding", "location_career"
        }:
            sort_key = "total"
        rows.sort(key=lambda x: x.get(sort_key, 0), reverse=True)
        rows = rows[:top_n]

        lines = [
            f"ğŸ“Š æ‹©æ ¡è¯„åˆ†å¡ï¼ˆå…± {len(rows)} æ¡ï¼ŒæŒ‰ {sort_key} æ’åºï¼‰",
            f"æƒé‡: {json.dumps(weights, ensure_ascii=False)}",
            "",
            "å­¦æ ¡ | é¡¹ç›® | æ€»åˆ† | ç ”ç©¶åŒ¹é… | å½•å–å¯è¡Œæ€§ | æˆæœ¬èµ„åŠ© | åŒºä½å°±ä¸š | åˆ†å±‚",
            "---|---|---:|---:|---:|---:|---:|---",
        ]
        for r in rows:
            lines.append(
                f"{r['school']} | {r['program']} | {r['total']:.1f} | "
                f"{r['research_fit']:.1f} | {r['admission_feasibility']:.1f} | "
                f"{r['cost_funding']:.1f} | {r['location_career']:.1f} | {r['tier']}"
            )

        lines.append("")
        lines.append("åˆ†å±‚è§„åˆ™: admission_feasibility <45=å†²åˆº, 45-69.9=åŒ¹é…, >=70=ä¿åº•")
        return "\n".join(lines)
    except Exception as e:
        return f"âŒ è¯„åˆ†å¡ç”Ÿæˆå¤±è´¥: {e}"


grad_application_timeline_schema = {
    "type": "function",
    "function": {
        "name": "grad_application_timeline",
        "description": (
            "åŸºäºæ¡£æ¡ˆæˆªæ­¢æ—¶é—´ç”Ÿæˆç”³è¯·æ—¶é—´çº¿ï¼Œå¯é€‰å†™å…¥æé†’äº‹é¡¹ã€‚"
        ),
        "parameters": {
            "type": "object",
            "properties": {
                "schools": {"type": "string", "description": "å­¦æ ¡ååˆ—è¡¨ï¼Œé€—å·åˆ†éš”ï¼›ç•™ç©ºè¡¨ç¤ºå…¨éƒ¨æ¡£æ¡ˆ"},
                "program": {"type": "string", "description": "é™å®šä¸“ä¸šï¼ˆå¯é€‰ï¼‰"},
                "start_date": {"type": "string", "description": "èµ·å§‹æ—¥æœŸï¼Œæ ¼å¼ YYYY-MM-DDï¼Œé»˜è®¤ä»Šå¤©"},
                "target_deadline": {"type": "string", "description": "æ‰‹åŠ¨æŒ‡å®šæœ€æ—©ç”³è¯·æˆªæ­¢æ—¥æœŸï¼ˆå¯é€‰ï¼‰"},
                "create_reminders": {"type": "boolean", "description": "æ˜¯å¦å†™å…¥æé†’ï¼Œé»˜è®¤ false"},
                "reminder_time": {"type": "string", "description": "æé†’æ—¶é—´ï¼Œæ ¼å¼ HH:MMï¼Œé»˜è®¤ 09:00"}
            },
            "required": []
        }
    }
}


@register(grad_application_timeline_schema)
def grad_application_timeline(
    schools: str = "",
    program: str = "",
    start_date: str = "",
    target_deadline: str = "",
    create_reminders: bool = False,
    reminder_time: str = "09:00",
):
    try:
        profiles = _load_profiles()
        if not profiles:
            return "âŒ æ²¡æœ‰æ¡£æ¡ˆæ•°æ®ï¼Œè¯·å…ˆå½•å…¥æ‹©æ ¡æ¡£æ¡ˆã€‚"

        selected = _filter_profiles(profiles, schools=schools, program=program)
        if not selected:
            return "âŒ æœªç­›é€‰åˆ°ä»»ä½•æ¡£æ¡ˆã€‚"

        start_dt = _parse_date(start_date) if start_date else datetime.now()
        if not start_dt:
            return "âŒ start_date æ ¼å¼é”™è¯¯ï¼Œç¤ºä¾‹: 2026-02-17"

        deadlines = []
        manual_deadline = _parse_date(target_deadline) if target_deadline else None
        if manual_deadline:
            deadlines.append(("æ‰‹åŠ¨æŒ‡å®š", manual_deadline))

        for p in selected:
            dt = _extract_deadline(p)
            if dt:
                tag = f"{p.get('school', '?')} - {p.get('program', '?')}"
                deadlines.append((tag, dt))

        if not deadlines:
            return (
                "âŒ æœªå‘ç°å¯ç”¨ deadlineã€‚è¯·åœ¨æ¡£æ¡ˆ info_json ä¸­è¡¥å…… application_deadline/deadlineï¼Œ"
                "æˆ–ä¼ å…¥ target_deadlineã€‚"
            )

        deadlines.sort(key=lambda x: x[1])
        final_deadline = deadlines[0][1]
        if final_deadline < start_dt:
            return f"âŒ æˆªæ­¢æ—¥æœŸ {final_deadline.strftime('%Y-%m-%d')} æ—©äºèµ·å§‹æ—¥æœŸ"

        reminder_time = (reminder_time or "09:00").strip()
        if not re.fullmatch(r"\d{2}:\d{2}", reminder_time):
            return "âŒ reminder_time æ ¼å¼é”™è¯¯ï¼Œç¤ºä¾‹: 09:00"

        milestones = [
            (180, "ç”³è¯·å®šä½å®šç¨¿ï¼šç¡®å®šå†²åˆº/åŒ¹é…/ä¿åº•åå•ï¼Œæ£€æŸ¥ç¡¬æ€§è¦æ±‚"),
            (120, "å®Œæˆè€ƒè¯•ä¸èƒŒæ™¯ææ–™å‡†å¤‡ï¼šæ ‡åŒ–ã€æˆç»©å•ã€ç§‘ç ”/å®ä¹ è¯æ˜"),
            (90, "å®Œæˆ PS/SOP ä¸ç®€å†åˆç¨¿ï¼Œç¡®è®¤æ¨èäººå¹¶æ²Ÿé€šæ¨èæ—¶é—´"),
            (60, "å®Œæˆç½‘ç”³ææ–™äºŒè½®æ‰“ç£¨ï¼šæ–‡ä¹¦ã€æ¨èä¿¡ä¿¡æ¯ã€è¡¥å……é—®é¢˜"),
            (30, "æäº¤å‰ç»ˆå®¡ï¼šæ ¼å¼ã€é€»è¾‘ã€è¯æ˜æ–‡ä»¶ã€ç¼´è´¹ä¸ç³»ç»ŸçŠ¶æ€"),
            (14, "å®Œæˆä¸»è¦é¡¹ç›®æäº¤å¹¶å‡†å¤‡é¢è¯•é—®ç­”ï¼ˆç ”ç©¶åŠ¨æœº/é¡¹ç›®ç»å†ï¼‰"),
            (7, "æŸ¥æ¼è¡¥ç¼ºï¼šç¡®è®¤æäº¤å›æ‰§ã€è¡¥ä»¶çŠ¶æ€ã€é¢è¯•æ—¶é—´å®‰æ’"),
        ]

        lines = [
            "ğŸ—“ï¸ ç”³è¯·æ—¶é—´çº¿",
            f"èµ·å§‹æ—¥æœŸ: {start_dt.strftime('%Y-%m-%d')}",
            f"å…³é”®æˆªæ­¢: {final_deadline.strftime('%Y-%m-%d')}",
            f"æ€»è®¡æ—¶é•¿: {(final_deadline - start_dt).days} å¤©",
            "",
            "å„é¡¹ç›®æˆªæ­¢æ—¶é—´ï¼š",
        ]
        for tag, dt in deadlines[:20]:
            lines.append(f"- {tag}: {dt.strftime('%Y-%m-%d')}")

        lines.append("")
        lines.append("é‡Œç¨‹ç¢‘è®¡åˆ’ï¼š")

        reminder_payloads = []
        for days_before, task in milestones:
            d = final_deadline - timedelta(days=days_before)
            if d < start_dt:
                continue
            dstr = d.strftime("%Y-%m-%d")
            lines.append(f"- {dstr}: {task}")
            reminder_payloads.append((dstr, task))

        # Always include final deadline reminder.
        final_str = final_deadline.strftime("%Y-%m-%d")
        final_task = "æœ€ç»ˆæäº¤æˆªæ­¢æ—¥ï¼šç¡®è®¤æ‰€æœ‰ç”³è¯·çŠ¶æ€ä¸ºå·²æäº¤"
        lines.append(f"- {final_str}: {final_task}")
        reminder_payloads.append((final_str, final_task))

        if create_reminders and reminder_payloads:
            from .daily_tools import reminder_manage

            ok = 0
            errs = []
            for dstr, task in reminder_payloads:
                resp = reminder_manage(
                    action="add",
                    content=f"[ç”³è¯·æ—¶é—´çº¿] {task}",
                    remind_time=f"{dstr} {reminder_time}",
                )
                if isinstance(resp, str) and resp.startswith("âœ…"):
                    ok += 1
                else:
                    errs.append(str(resp))

            lines.append("")
            lines.append(f"æé†’å†™å…¥: {ok}/{len(reminder_payloads)}")
            if errs:
                lines.append("æé†’å¼‚å¸¸æ ·ä¾‹:")
                lines.extend([f"- {e}" for e in errs[:5]])

        return "\n".join(lines)
    except Exception as e:
        return f"âŒ ç”³è¯·æ—¶é—´çº¿ç”Ÿæˆå¤±è´¥: {e}"
